<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GLASS: Guided Latent Slot Diffusion for Object-Centric Learning">
  <meta name="keywords" content="Object-Centric learning, OCL, compositional learning, diffusion, generative">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GLASS: Guided Latent Slot Diffusion for Object-Centric Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Helvetica"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title section-title">GLASS: Guided Latent Slot Diffusion for Object-Centric Learning</h1>
          <div class="is-size-5 publication-authors">
            <div class="is-size-5 publication-authors">
              <h2 class="subtitle is-3">CVPR 2025</h2>
            <span class="author-block">
              <a href="https://kris-singh.github.io/">Krishnakant Singh</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://schaubsi.github.io/">Simone Schaub-Meyer</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.visinf.tu-darmstadt.de/visual_inference/people_vi/stefan_roth.en.jsp">Stefan Roth</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1 </sup>Technical Univeristy of Darmstadt,</span>
            <span class="author-block"><sup>2 </sup>hessian.AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Singh_GLASS_Guided_Latent_Slot_Diffusion_for_Object-Centric_Learning_CVPR_2025_paper.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                </a>
            </span>
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Singh_GLASS_Guided_Latent_Slot_Diffusion_for_Object-Centric_Learning_CVPR_2025_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/visinf/glass"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://youtu.be/watch?v=n7JCtkmxP3A" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Object-centric learning aims to decompose an input image into a set of meaningful object files (slots). 
          These latent object representations enable a variety of downstream tasks. 
          Yet, object-centric learning struggles on real-world datasets, which contain multiple objects of complex textures and shapes in natural everyday scenes. 
          To address this, we introduce <b>G</b>uided <b>La</b>tent <b>S</b>lot Diffu<b>s</b>ion (GLASS), a novel slot-attention model that learns in the space of generated images and uses semantic and instance guidance modules to learn better slot embeddings for various downstream tasks.
          Our experiments show that GLASS surpasses state-of-the-art slot-attention methods by a wide margin on tasks such as (zero-shot) object discovery and conditional image generation for real-world scenes.
          Moreover, GLASS enables the first application of slot attention to the compositional generation of complex, realistic scenes.        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <img src="./static/images/favicon.png" width="30px" style="padding-left:0px; vertical-align: middle;">
          GLASS at a glance
        </h2>
        <div id="wrapper">
          <img src="./static/images/glass_at_glance.png" width="450px">
      </div>
      <br>
        <div class="content has-text-justified">
          GLASS is an object-centric representation model that uses a diffusion decoder. 
          GLASS learns in the space of generated images, allowing it to leverage the semantic guidance from a diffusion decoder and instance guidance from a DINOv2 encoder.  
        </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
        <p> GLASS is a object-centric representation learning method that performs multiple downstream tasks like object discovery, compositional generation, conditional generation. and property prediction.
          We show results for all the tasks.
        </p>

      </div>
    </div>
   </div>
    <!--/ Matting. -->

    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Object Discovery</h2>
        <div class="content has-text-justified">
          <p>
GLASS outperforms existing object-centric learning (OCL) methods on the task of object discovery.
          </p>
          <div id="wrapper">
          <img src="./static/images/od_quant.png" width="500px">
          </div>
         </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <p>
          GLASS obtains cleaner boundaries and better object-level segmentation compared to existing OCL methods.
        </p>
        <div id="wrapper">
          <img src="./static/images/qual_od.png" width="450px">
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Compositional Generation</h2>

        <div class="content has-text-justified">
          <p>
            GLASS is the first object-centric model to enable compositional generation (addition and removal of objects) for realistic scenes.
          </p>
            <p>
              <b>Object Removal:</b> GLASS is able to remove the highlted object (red) from the scene while preserving the rest of the scene.
            </p>
          <div id="wrapper">
            <img src="./static/images/comp_gen_remove.png" width="380px">
          </div>
          <p>
            <b>Object Addition:</b> GLASS is able to add the highlighted object (red) to a new scene while preserving the rest of the scene.
          </p>
          <div id="wrapper">
            <img src="./static/images/comp_gen_add.png" width="380px">
          </div>

        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conditional Generation</h2>
          <p>
            GLASS outperforms StableLSD on the task of conditional generation.
            Producing much higher quality images than StableLSD.
          </p>
          <br>
        <div class="content has-text-justified">
          <div id="wrapper">
          <img src="./static/images/cond_gen_qual.png" width="380px">
          </div>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Object-level Property Prediction</h2>

        <div class="content has-text-justified">
          <p>
            GLASS outperforms StableLSD on the task of object-level property prediction.
            Note: StableLSD is the closest model in terms of downstream task capabilities.
          </p>
          <div id="wrapper">
            <img src="./static/images/downstream.png" width="450px">
          </div>
        </div>
      </div>
    </div>

</div>


</div>

</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{singh2025glass,
  author    = {Krishnakant Singh and Simone Scahub-Meyer and Stefan Roth},
  title     = {GLASS: Guided Latent Slot Diffusion for Object-Centric Learning},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
      The website template is borrowed from the awesome <a href="https://github.com/nerfies/nerfies.github.io"> Nerfies</a> website.
      </p>
        </div>
      </div>
    </div>
   </div>
  </div>
</footer>

</body>
</html>
